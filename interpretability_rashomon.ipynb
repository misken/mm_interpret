{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ab795-01d3-4752-922c-e7456ecc1ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b7fd92f-35f2-4810-8c48-e543b1c27536",
   "metadata": {},
   "source": [
    "## Background notes and refs on interpetability and Rashomon effect\n",
    "\n",
    "The following is the MIT Review article and the original on using neural nets to solve PDEs. What's relevant here is that they used the physics insight that they should Fourier transform the inputs.\n",
    "\n",
    "https://www.technologyreview.com/2020/10/30/1011435/ai-fourier-neural-network-cracks-navier-stokes-and-partial-differential-equations/\n",
    "\n",
    "https://arxiv.org/abs/2010.08895\n",
    "\n",
    "https://statmodeling.stat.columbia.edu/2021/04/12/is-explainability-the-new-uncertainty/\n",
    "\n",
    "https://statmodeling.stat.columbia.edu/2021/06/30/not-being-able-to-say-why-you-see-a-2-doesnt-excuse-your-uninterpretable-model/\n",
    "\n",
    "https://www.statcan.gc.ca/eng/data-science/network/decision-making%20/\n",
    "\n",
    "https://www.quantamagazine.org/science-has-entered-a-new-era-of-alchemy-good-20211020/?mc_cid=a1644c0083&mc_eid=508de67bb8\n",
    "\n",
    "Discusses the current state of lack of understanding of AI algorithms\n",
    "\n",
    "\n",
    "The StatCan article is super relevant. Good summary of what makes a model \"simple\" and the advantages of such models in certain domains over more complex black-box models. The article is linked to from the Gelman post above.\n",
    "\n",
    "* \"Rashomon effect\" (Breiman, 2001) (downloaded already)\n",
    "* \"A recent study (Semenova et al., 2019), now supports running a set of different (mostly black box) ML models to determine their relative accuracy on a given data set to predict the existence of a simple accurate interpretable model—that is, a way to quickly identify applications where it is a good bet that accurate interpretable prediction model can be developed.\" (downloaded already)\n",
    "* \"There is now a vast and confusing literature, which conflates interpretability and explainability. \"\n",
    "\n",
    "Breiman, L. (2001). Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author). Statist. Sci. 16(3): 199-231. DOI: 10.1214/ss/1009213726\n",
    "\n",
    "Ennis, M., Hinton, G., Naylor, D., Revow, M., and Tibshirani, R. (1998). A Comparison of Statistical Learning Methods on the Gusto Database. Statistics. Med. 17, 2501-2508. A comparison of statistical learning methods on the GUSTO database\n",
    "\n",
    "Erasmus, A., Bruent, T.D.P., and Fisher E. (2020). What is Interpretability? Philosophy & Technology. What is Interpretability?\n",
    "\n",
    "Ericsson, K. A., & Simon, H. A. (1980). Verbal reports as data. Psychological Review, 87(3), 215–251. Verbal reports as data.\n",
    "\n",
    "Government of Canada. (2021). Guideline on Service and Digital. Guideline on Service and Digital. [Accessed: May 13, 2021].\n",
    "\n",
    "Gu, Y., and Dunson, D.B. (2021). Identifying Interpretable Discrete Latent Structures from Discrete Data. arXiv:2101.10373 [stat.ME]\n",
    "\n",
    "Hinton, G. (2018). Why Is a Two a Two? Why Is A Two A Two? With Geoffrey Hinton and David Naylor [Accessed: May 13, 2021].\n",
    "\n",
    "Hamamoto, R., Suvarna, K., Yamada, M., Kobayashi, K., Shinkai, N., Miyake, M., Takahashi, M., Jinnai, S., Shimoyama, R., Sakai, A., Taksawa, K., Bolatkan, A., Shozu, K., Dozen, A., Machino, H., Takahashi, S., Asada, K., Komasu, M., Sese, J., and Kaneko., S. (2020). Application of Artificial Intelligence Technology in Oncology: Towards the Establishment of Precision Medicine. Cancers. 12(12), 3532; Application of Artificial Intelligence Technology in Oncology: Towards the Establishment of Precision Medicine\n",
    "\n",
    "Lakkaraju, H., and Bastani, O. (2019). \"How do I fool you?\": Manipulating User Trust via Misleading Black Box Explanations. arXiv:1911.06473 [cs.AI]\n",
    "\n",
    "Rudin, C., Chen, C., Chen, Z., Huang, H., Semenova, L., and Zhong, C. (2021). Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges. arXiv:2103.11251 [cs.LG]\n",
    "\n",
    "Rudin, C., & Radin, J. (2019). Why Are We Using Black Box Models in AI When We Don't Need To? A Lesson From An Explainable AI Competition. Harvard Data Science Review, 1(2). Why Are We Using Black Box Models in AI When We Don't Need To? A Lesson From An Explainable AI Competition\n",
    "\n",
    "Semenova, R., Rudin, C., and Parr, R. (2019). A study in Rashomon curves and volumes: A new perspective on generalization and model simplicity in machine learning. arXiv:1908.01755 [cs.LG]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439bc1c7-8afd-44c1-8e1f-f277933953fa",
   "metadata": {},
   "source": [
    "Breiman (2001) - Statistical Modeling: The Two Cultures\n",
    "\n",
    "* Rashomon: the multiplicity of good models;\n",
    "* Occam: the conflict between simplicity accuracy;\n",
    "* Bellman: dimensionality—curse or blessing?\n",
    "\n",
    "Goodness of fit tests and residual analysis are fraught with issues for problems with numerous predictors, especially when interactions and non-linear transformations are used.\n",
    "    \n",
    "> McCullah and Nelder (1989) write “Data will often point with almost equal emphasis on several possible models, and it is important that thestatistician recognize and accept this.”\n",
    "\n",
    "> With the insistence on data models, multivariate\n",
    "analysis tools in statistics are frozen at discriminant\n",
    "analysis and logistic regression in classification and\n",
    "multiple linear regression in regression. Nobody\n",
    "really believes that multivariate data is multivari-\n",
    "ate normal, but that data model occupies a large\n",
    "number of pages in every graduate textbook on\n",
    "multivariate statistical analysis.\n",
    "\n",
    ">Perhaps the damaging consequence of the insis-\n",
    "tence on data models is that statisticians have ruled\n",
    "themselves out of some of the most interesting and\n",
    "challenging statistical problems that have arisen\n",
    "out of the rapidly increasing ability of computers\n",
    "to store and manipulate data. These problems are\n",
    "increasingly present in many fields, both scientific\n",
    "and commercial, and solutions are being found by\n",
    "nonstatisticians.\n",
    "\n",
    ">But the trick to being a scientist is to\n",
    "be open to using a wide variety of tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7114a5-3f53-4522-b214-b78d2f624069",
   "metadata": {},
   "source": [
    "## AI for poker strategy\n",
    "https://www.nytimes.com/2022/01/18/magazine/ai-technology-poker.html\n",
    "\n",
    "Talks about how AI algos don't explain how they got to optimal strategies. Players have to try to reverse-engineer the AI outcomes to get to a strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef71a35b-9d16-41e8-be74-5b69ff8db3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b24eac1-48d6-4bf8-af50-5e1be16d7d8b",
   "metadata": {},
   "source": [
    "### Rashomon effect\n",
    "\n",
    ">The multiplicity problem\n",
    "and its effect on conclusions drawn from models\n",
    "needs serious attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f5416-3e59-4f41-ba5b-ac3f6c5cb4d5",
   "metadata": {},
   "source": [
    "A New Perspective on Generalization and\n",
    "Model Simplicity in Machine Learning\n",
    "Lesia Semenova 1 , Cynthia Rudin 2 , and Ronald Parr 1\n",
    "1 Duke\n",
    "University, Department of Computer Science, Durham, NC, 27708, USA\n",
    "University, Departments of Computer Science, Electrical and Computer Engineering, and Statistical Science,\n",
    "Durham, NC, 27708, USA\n",
    "2 Duke\n",
    "ABSTRACT\n",
    ">The Rashomon effect occurs when many different explanations exist for the same phenomenon. In machine learning, Leo\n",
    "Breiman used this term to characterize problems where many accurate-but-different models exist to describe the same data.\n",
    "In this work, we study how the Rashomon effect can be useful for understanding the relationship between training and test\n",
    "performance, and the possibility that simple-yet-accurate models exist for many problems. We consider the Rashomon set—the\n",
    "set of almost-equally-accurate models for a given problem—and study its properties and the types of models it could contain.\n",
    "We present the Rashomon ratio as a new measure related to simplicity of model classes, which is the ratio of the volume of\n",
    "the set of accurate models to the volume of the hypothesis space; the Rashomon ratio is different from standard complexity\n",
    "measures from statistical learning theory. For a hierarchy of hypothesis spaces, the Rashomon ratio can help modelers\n",
    "to navigate the trade-off between simplicity and accuracy. In particular, we find empirically that a plot of empirical risk vs.\n",
    "Rashomon ratio forms a characteristic Γ-shaped Rashomon curve, whose elbow seems to be a reliable model selection\n",
    "criterion. When the Rashomon set is large, models that are accurate—but that also have various other useful properties—may\n",
    "often be obtained. These models might obey various constraints such as interpretability, fairness, or monotonicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72842cf1-3a31-4450-88d9-c771b8f9281c",
   "metadata": {},
   "source": [
    "### Occam's Razor\n",
    "\n",
    ">Accuracy generally requires more complex pre-\n",
    "diction methods. Simple and interpretable functions\n",
    "do not make the most accurate predictors.\n",
    "\n",
    "Maybe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c213475-91e6-4ba8-8e4f-3eaed9a01186",
   "metadata": {},
   "source": [
    "### Bellman's Curse\n",
    "\n",
    ">Instead of reducing dimensionality, increase it\n",
    "by adding many functions of the predictor variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7ced9-3d2a-4928-b773-15b9428b96f4",
   "metadata": {},
   "source": [
    "https://www.iunera.com/kraken/fabric/random-forest-vs-support-vector-machine-vs-neural-network/\n",
    "\n",
    ">More data beats clever algorithms, but better and cleaner data beats more data.\n",
    "    Peter Norvik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35c215-4a3b-4235-97fc-15d4e6ab1382",
   "metadata": {},
   "source": [
    "## Revisiting Rashomon\n",
    "https://arxiv.org/pdf/2104.02150.pdf\n",
    "\n",
    "@article{d2021revisiting,\n",
    "  title={Revisiting Rashomon: A Comment on\" The Two Cultures\"},\n",
    "  author={D'Amour, Alexander},\n",
    "  journal={arXiv preprint arXiv:2104.02150},\n",
    "  year={2021}\n",
    "}\n",
    "\n",
    "Modern perspective from both sides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37efa5c-0a76-4be8-a8ae-ad21198ab158",
   "metadata": {},
   "source": [
    "### Rudin, C., Chen, C., Chen, Z., Huang, H., Semenova, L., and Zhong, C. (2021). Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges. arXiv:2103.11251 [cs.LG]\n",
    "\n",
    "Good background on practical importance of interpretable models.\n",
    "\n",
    "\"There is a clear need for innovative machine learning models that are inherently interpretable.\"\n",
    "\n",
    "> Interpretability penalties or con-\n",
    "straints can include sparsity of the model, monotonicity with respect to a variable, decomposibility\n",
    "into sub-models, an ability to perform case-based reasoning or other types of visual comparisons,\n",
    "disentanglement of certain types of information within the model’s reasoning process, generative\n",
    "constraints (e.g., laws of physics), preferences among the choice of variables, or any other type\n",
    "of constraint that is relevant to the domain. Just as it would be futile to create a complete list of\n",
    "performance metrics for machine learning, any list of interpretability metrics would be similarly fated.\n",
    "\n",
    "* Sparsity is often important for interpretability in problems with tabular data (no so important for things like image processing).\n",
    "\n",
    "* Interpetability more important for high stakes decisions. \n",
    "\n",
    "> An important point about interpretable machine learning models is that there is no scientific\n",
    "evidence for a general tradeoff between accuracy and interpretability when one considers the full\n",
    "data science process for turning data into knowledge. \n",
    "\n",
    "* For example, interpetability can lead to easier troubleshooting which can lead to more accurate models.\n",
    "\n",
    "> **Principle 3** It is important not to assume that one needs to make a sacrifice in accuracy in order\n",
    "to gain interpretability. In fact, interpretability often begets accuracy, and not the reverse. Interpretability versus accuracy is, in general, a false dichotomy in machine learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be14a39-1f71-45da-8c60-541f53d94a42",
   "metadata": {},
   "source": [
    "### Many models often perform well on tabular data\n",
    "\n",
    "My results support this.\n",
    "\n",
    "> For tabular data, most machine learning algorithms tend to perform similarly in terms of pre-\n",
    "diction accuracy. This means it is often difficult even to beat logistic regression, assuming one is\n",
    "willing to perform minor preprocessing such as creating dummy variables (e.g., see Christodoulou\n",
    "et al., 2019). In these domains, neural networks generally find no advantage. It has been known\n",
    "for a very long time that very simple models perform surprisingly well for tabular data (Holte,\n",
    "1993). The fact that simple models perform well for tabular data could arise from the Rashomon\n",
    "Effect discussed by Leo Breiman (Breiman et al., 2001). Breiman posits the possibility of a large\n",
    "Rashomon set, i.e., a multitude of models with approximately the minumum error rate, for many\n",
    "problems. Semenova et al. (2019) show that as long as a large Rashomon set exists, it is more\n",
    "likely that some of these models are interpretable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e89c80-5fd3-4e1c-9df3-6702f22d6e91",
   "metadata": {},
   "source": [
    "### Explainability\n",
    "\n",
    "explainability != interpetability though conflated in some literature\n",
    "\n",
    "* Explainable AI (XAI) can be similar to simulation metamodeling in which more complex model \"explained\" by simpler approximating model. Things like variable importance measures also are part of XAI. Unfortunately, explanations can be problematic and misleading.\n",
    "\n",
    "> In that sense, explainability methods are often used as an excuse to use a black box model–\n",
    "whether or not one is actually needed. Explainability techniques give authority to black box models\n",
    "rather than suggesting the possibility of models that are understandable in the first place (Rudin\n",
    "and Radin, 2019).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94754915-35e5-407f-9969-d600658fd913",
   "metadata": {},
   "source": [
    "## 1 Sparse Logical Models: Decision Trees, Decision Lists, and Decision Sets\n",
    "\n",
    "Interesting discussion of recent work on optimization based approaches to constructing decision trees that do better than the greedy heuristics using in CART and similar. OR is a big part of data science.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c283e48-9d9f-4165-a79c-469b6b9dbcc8",
   "metadata": {},
   "source": [
    "## 3 Generalized Additive Models\n",
    "\n",
    "GAMs tend to use univariate functions such as step functions, polynomials or splines. Some of my metamodels use multivariate functions such as erlang C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb3d512-0b30-47e8-87c3-4f0c4e70e210",
   "metadata": {},
   "source": [
    "## 4 Modern case-based reasoning\n",
    "\n",
    "> Case-based reasoning is a paradigm that involves solving a new problem using known solutions\n",
    "to similar past problems (Aamodt and Plaza, 1994). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f5266-90a1-47eb-b72c-51bea91e17ff",
   "metadata": {},
   "source": [
    "## 8 Machine learning models that incorporate physics and other generative or causal constraints\n",
    "\n",
    "> There is a growing trend towards developing machine learning models that incorporate physics\n",
    "(or other) constraints. These models are not purely data-driven, in the sense that their training\n",
    "may require little data or no data at all (e.g., Rao et al., 2020). Instead, these models are trained\n",
    "to observe physical laws, often in the form of ordinary (ODEs) and partial differential equations\n",
    "(PDEs). These physics-guided models provide alternatives to traditional numerical methods (e.g.,\n",
    "finite element methods) for solving PDEs, and are of immense interest to physicists, chemists, and\n",
    "materials scientists. The resulting models are interpretable, in the sense that they are constrained\n",
    "to follow the laws of physics that were provided to them. (It might be easier to think conversely:\n",
    "physicists might find that a standard supervised machine learning model that is trained on data from\n",
    "a known physical system – but that does not follow the laws of physics – would be uninterpretable.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb3f58-1b64-447d-95e4-c4b8fc6941a7",
   "metadata": {},
   "source": [
    "## 9 Characterization of the “Rashomon” set of good models\n",
    "\n",
    "> In many practical machine learning problems, there is a multiplicity of almost-equally-accurate\n",
    "models. This set of high performing models is called the Rashomon set, based on an observation of\n",
    "the Rashomon effect by the statistician Leo Breiman. The Rashomon effect occurs when there are\n",
    "multiple descriptions of the same event (Breiman et al., 2001) with possibly no ground truth.\n",
    "\n",
    "> Semenova et al. (2019) also suggested a useful rule of thumb for determining whether a\n",
    "Rashomon set is large: run many different types of machine learning algorithms (e.g., boosted\n",
    "decision trees, support vector machines, neural networks, random forests, logistic regression) and\n",
    "if they generally perform similarly, it correlates with the existence of a large Rashomon set (and\n",
    "thus the possibility of a simpler function also achieving a similar level of accuracy). The knowl-\n",
    "edge that there might exist a simple-yet-accurate function before finding it could be very useful,\n",
    "particularly in the cases where finding an optimal sparse model is NP-hard, as in Challenge 1.\n",
    "Here, the user would run many different algorithms to determine whether it would be worthwhile\n",
    "to solve the hard problem of finding an interpretable sparse model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
